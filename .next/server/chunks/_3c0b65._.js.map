{
  "version": 3,
  "sections": [
    {"offset": {"line": 5, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/intake/normalize.ts"],"sourcesContent":["export function normalizeInput(text: string): string {\r\n  return text\r\n    .replace(/\\r\\n/g, \"\\n\")\r\n    .replace(/\\t/g, \" \")\r\n    .replace(/\\s{2,}/g, \" \")\r\n    .trim();\r\n}\r\n"],"names":[],"mappings":";;;AAAO,SAAS,eAAe,IAAY;IACzC,OAAO,KACJ,OAAO,CAAC,SAAS,MACjB,OAAO,CAAC,OAAO,KACf,OAAO,CAAC,WAAW,KACnB,IAAI;AACT"}},
    {"offset": {"line": 11, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 16, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/intake/tone-calibration.ts"],"sourcesContent":["export type Tone =\r\n  | \"neutral\"\r\n  | \"confident\"\r\n  | \"assertive\"\r\n  | \"speculative\";\r\n\r\nexport function calibrateTone(text: string): Tone {\r\n  const confidenceMarkers = [\"clearly\", \"definitely\", \"proven\"];\r\n  const speculativeMarkers = [\"might\", \"could\", \"possibly\"];\r\n\r\n  if (confidenceMarkers.some(w => text.includes(w))) return \"assertive\";\r\n  if (speculativeMarkers.some(w => text.includes(w))) return \"speculative\";\r\n\r\n  return \"neutral\";\r\n}\r\n"],"names":[],"mappings":";;;AAMO,SAAS,cAAc,IAAY;IACxC,MAAM,oBAAoB;QAAC;QAAW;QAAc;KAAS;IAC7D,MAAM,qBAAqB;QAAC;QAAS;QAAS;KAAW;IAEzD,IAAI,kBAAkB,IAAI,CAAC,CAAA,IAAK,KAAK,QAAQ,CAAC,KAAK,OAAO;IAC1D,IAAI,mBAAmB,IAAI,CAAC,CAAA,IAAK,KAAK,QAAQ,CAAC,KAAK,OAAO;IAE3D,OAAO;AACT"}},
    {"offset": {"line": 34, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 39, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/intake/domain-classifier.ts"],"sourcesContent":["export type Domain =\r\n  | \"product\"\r\n  | \"finance\"\r\n  | \"legal\"\r\n  | \"research\"\r\n  | \"general\";\r\n\r\nexport function classifyDomain(text: string): Domain {\r\n  const t = text.toLowerCase();\r\n\r\n  if (t.includes(\"regulation\") || t.includes(\"law\")) return \"legal\";\r\n  if (t.includes(\"revenue\") || t.includes(\"market\")) return \"finance\";\r\n  if (t.includes(\"experiment\") || t.includes(\"study\")) return \"research\";\r\n  if (t.includes(\"user\") || t.includes(\"feature\")) return \"product\";\r\n\r\n  return \"general\";\r\n}\r\n"],"names":[],"mappings":";;;AAOO,SAAS,eAAe,IAAY;IACzC,MAAM,IAAI,KAAK,WAAW;IAE1B,IAAI,EAAE,QAAQ,CAAC,iBAAiB,EAAE,QAAQ,CAAC,QAAQ,OAAO;IAC1D,IAAI,EAAE,QAAQ,CAAC,cAAc,EAAE,QAAQ,CAAC,WAAW,OAAO;IAC1D,IAAI,EAAE,QAAQ,CAAC,iBAAiB,EAAE,QAAQ,CAAC,UAAU,OAAO;IAC5D,IAAI,EAAE,QAAQ,CAAC,WAAW,EAAE,QAAQ,CAAC,YAAY,OAAO;IAExD,OAAO;AACT"}},
    {"offset": {"line": 50, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 55, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/claims/claim-decomposer.ts"],"sourcesContent":["// core/claims/claim-decomposer.ts\r\nimport { createHash } from \"crypto\";\r\nimport { ClaimType } from \"./claim-types\";\r\nimport { LLMProvider } from \"../../lib/llm/provider-adapter\";\r\n\r\nexport type AuditGravity = \"critical\" | \"high\" | \"medium\" | \"low\";\r\n\r\nexport type Claim = {\r\n  id: string;\r\n  text: string;\r\n  index: number;\r\n  type: ClaimType;\r\n  gravity: AuditGravity; // Moved from 'confidence' to 'gravity'\r\n  confidence: number;\r\n};\r\n\r\nexport async function decomposeClaimsAdvanced(\r\n  content: string,\r\n  provider: LLMProvider\r\n): Promise<Claim[]> {\r\n  const prompt = `\r\n    Act as a Senior Forensic Auditor (ex-McKinsey/SEC). \r\n    Decompose the following text into distinct, atomic claims.\r\n    \r\n    For each claim, identify:\r\n    1. The core assertion.\r\n    2. Type: factual | causal | normative | predictive | numerical.\r\n    3. Audit Gravity: \r\n       - critical: Violations of physics, law, or absolute guarantees (e.g. \"100% returns\").\r\n       - high: Unsubstantiated high-impact stats or causal chains.\r\n       - medium/low: Standard professional assertions.\r\n\r\n    Return the result ONLY as a JSON array of objects:\r\n    { \"text\": string, \"type\": ClaimType, \"gravity\": AuditGravity }\r\n\r\n    Text to audit: \"${content}\"\r\n  `;\r\n\r\n  const response = await provider.generate({ prompt, temperature: 0 });\r\n  const rawClaims: any[] = JSON.parse(response.text);\r\n\r\n  return rawClaims.map((c, idx) => ({\r\n    ...c,\r\n    id: `C${idx + 1}`,\r\n    index: idx,\r\n    confidence: 1.0,\r\n  }));\r\n}"],"names":[],"mappings":"AAAA,kCAAkC;;;;AAgB3B,eAAe,wBACpB,OAAe,EACf,QAAqB;IAErB,MAAM,SAAS,CAAC;;;;;;;;;;;;;;;oBAeE,EAAE,QAAQ;EAC5B,CAAC;IAED,MAAM,WAAW,MAAM,SAAS,QAAQ,CAAC;QAAE;QAAQ,aAAa;IAAE;IAClE,MAAM,YAAmB,KAAK,KAAK,CAAC,SAAS,IAAI;IAEjD,OAAO,UAAU,GAAG,CAAC,CAAC,GAAG,MAAQ,CAAC;YAChC,GAAG,CAAC;YACJ,IAAI,CAAC,CAAC,EAAE,MAAM,EAAE,CAAC;YACjB,OAAO;YACP,YAAY;QACd,CAAC;AACH"}},
    {"offset": {"line": 89, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 94, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/claims/claim-linker.ts"],"sourcesContent":["import { Claim } from \"./claim-decomposer\";\r\n\r\nexport interface ClaimLink {\r\n  from: string;\r\n  to: string;\r\n}\r\n\r\nexport function linkClaims(claims: Claim[]): ClaimLink[] {\r\n  const links: ClaimLink[] = [];\r\n\r\n  for (let i = 1; i < claims.length; i++) {\r\n    links.push({\r\n      from: claims[i - 1].id,\r\n      to: claims[i].id,\r\n    });\r\n  }\r\n\r\n  return links;\r\n}\r\n"],"names":[],"mappings":";;;AAOO,SAAS,WAAW,MAAe;IACxC,MAAM,QAAqB,EAAE;IAE7B,IAAK,IAAI,IAAI,GAAG,IAAI,OAAO,MAAM,EAAE,IAAK;QACtC,MAAM,IAAI,CAAC;YACT,MAAM,MAAM,CAAC,IAAI,EAAE,CAAC,EAAE;YACtB,IAAI,MAAM,CAAC,EAAE,CAAC,EAAE;QAClB;IACF;IAEA,OAAO;AACT"}},
    {"offset": {"line": 107, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 112, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/reasoning/graph-builder.ts"],"sourcesContent":["// core/reasoning/graph-builder.ts\r\nimport { Claim } from \"../claims/claim-decomposer\";\r\nimport { ClaimLink } from \"../claims/claim-linker\";\r\n\r\nexport interface GraphStats {\r\n  isolatedNodes: string[];\r\n  bridgeCount: number;\r\n  depth: number;\r\n}\r\n\r\nexport interface ReasoningGraph {\r\n  nodes: Claim[];\r\n  edges: ClaimLink[];\r\n  stats: GraphStats;\r\n}\r\n\r\nexport function buildGraph(\r\n  claims: Claim[],\r\n  links: ClaimLink[]\r\n): ReasoningGraph {\r\n  // Identify isolated nodes (Claims with no incoming or outgoing support)\r\n  const linkedIds = new Set([\r\n    ...links.map(l => l.from),\r\n    ...links.map(l => l.to)\r\n  ]);\r\n  \r\n  const isolatedNodes = claims\r\n    .filter(c => !linkedIds.has(c.id))\r\n    .map(c => c.id);\r\n\r\n  return {\r\n    nodes: claims,\r\n    edges: links,\r\n    stats: {\r\n      isolatedNodes,\r\n      bridgeCount: links.length,\r\n      depth: calculateGraphDepth(links, claims)\r\n    }\r\n  };\r\n}\r\n\r\nfunction calculateGraphDepth(links: ClaimLink[], claims: Claim[]): number {\r\n  if (claims.length === 0) return 0;\r\n  // Simple heuristic for production: longest sequential path\r\n  const adj = new Map<string, string[]>();\r\n  links.forEach(l => {\r\n    const neighbors = adj.get(l.from) || [];\r\n    neighbors.push(l.to);\r\n    adj.set(l.from, neighbors);\r\n  });\r\n\r\n  let maxDepth = 0;\r\n  const visited = new Set<string>();\r\n\r\n  function dfs(id: string, currentDepth: number) {\r\n    maxDepth = Math.max(maxDepth, currentDepth);\r\n    visited.add(id);\r\n    (adj.get(id) || []).forEach(next => {\r\n      if (!visited.has(next)) dfs(next, currentDepth + 1);\r\n    });\r\n    visited.delete(id);\r\n  }\r\n\r\n  claims.forEach(c => dfs(c.id, 1));\r\n  return maxDepth;\r\n}"],"names":[],"mappings":"AAAA,kCAAkC;;;;AAgB3B,SAAS,WACd,MAAe,EACf,KAAkB;IAElB,wEAAwE;IACxE,MAAM,YAAY,IAAI,IAAI;WACrB,MAAM,GAAG,CAAC,CAAA,IAAK,EAAE,IAAI;WACrB,MAAM,GAAG,CAAC,CAAA,IAAK,EAAE,EAAE;KACvB;IAED,MAAM,gBAAgB,OACnB,MAAM,CAAC,CAAA,IAAK,CAAC,UAAU,GAAG,CAAC,EAAE,EAAE,GAC/B,GAAG,CAAC,CAAA,IAAK,EAAE,EAAE;IAEhB,OAAO;QACL,OAAO;QACP,OAAO;QACP,OAAO;YACL;YACA,aAAa,MAAM,MAAM;YACzB,OAAO,oBAAoB,OAAO;QACpC;IACF;AACF;AAEA,SAAS,oBAAoB,KAAkB,EAAE,MAAe;IAC9D,IAAI,OAAO,MAAM,KAAK,GAAG,OAAO;IAChC,2DAA2D;IAC3D,MAAM,MAAM,IAAI;IAChB,MAAM,OAAO,CAAC,CAAA;QACZ,MAAM,YAAY,IAAI,GAAG,CAAC,EAAE,IAAI,KAAK,EAAE;QACvC,UAAU,IAAI,CAAC,EAAE,EAAE;QACnB,IAAI,GAAG,CAAC,EAAE,IAAI,EAAE;IAClB;IAEA,IAAI,WAAW;IACf,MAAM,UAAU,IAAI;IAEpB,SAAS,IAAI,EAAU,EAAE,YAAoB;QAC3C,WAAW,KAAK,GAAG,CAAC,UAAU;QAC9B,QAAQ,GAAG,CAAC;QACZ,CAAC,IAAI,GAAG,CAAC,OAAO,EAAE,EAAE,OAAO,CAAC,CAAA;YAC1B,IAAI,CAAC,QAAQ,GAAG,CAAC,OAAO,IAAI,MAAM,eAAe;QACnD;QACA,QAAQ,MAAM,CAAC;IACjB;IAEA,OAAO,OAAO,CAAC,CAAA,IAAK,IAAI,EAAE,EAAE,EAAE;IAC9B,OAAO;AACT"}},
    {"offset": {"line": 155, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 160, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/reasoning/contradiction-checker.ts"],"sourcesContent":["import { Claim } from \"../claims/claim-decomposer\";\r\n\r\nexport function detectContradictions(claims: Claim[]): string[] {\r\n  const contradictions: string[] = [];\r\n\r\n  const texts = claims.map(c => c.text.toLowerCase());\r\n\r\n  if (\r\n    texts.some(t => t.includes(\"will happen\")) &&\r\n    texts.some(t => t.includes(\"will not happen\"))\r\n  ) {\r\n    contradictions.push(\"Direct future-state contradiction detected\");\r\n  }\r\n\r\n  return contradictions;\r\n}\r\n"],"names":[],"mappings":";;;AAEO,SAAS,qBAAqB,MAAe;IAClD,MAAM,iBAA2B,EAAE;IAEnC,MAAM,QAAQ,OAAO,GAAG,CAAC,CAAA,IAAK,EAAE,IAAI,CAAC,WAAW;IAEhD,IACE,MAAM,IAAI,CAAC,CAAA,IAAK,EAAE,QAAQ,CAAC,mBAC3B,MAAM,IAAI,CAAC,CAAA,IAAK,EAAE,QAAQ,CAAC,qBAC3B;QACA,eAAe,IAAI,CAAC;IACtB;IAEA,OAAO;AACT"}},
    {"offset": {"line": 171, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 176, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/reasoning/inference-gap-detector.ts"],"sourcesContent":["import { ReasoningGraph } from \"./graph-builder\";\r\n\r\nexport function detectInferenceGaps(graph: ReasoningGraph): string[] {\r\n  const gaps: string[] = [];\r\n\r\n  if (graph.nodes.length > 1 && graph.edges.length === 0) {\r\n    gaps.push(\"Claims are not logically connected\");\r\n  }\r\n\r\n  return gaps;\r\n}\r\n"],"names":[],"mappings":";;;AAEO,SAAS,oBAAoB,KAAqB;IACvD,MAAM,OAAiB,EAAE;IAEzB,IAAI,MAAM,KAAK,CAAC,MAAM,GAAG,KAAK,MAAM,KAAK,CAAC,MAAM,KAAK,GAAG;QACtD,KAAK,IAAI,CAAC;IACZ;IAEA,OAAO;AACT"}},
    {"offset": {"line": 186, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 191, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/engines/grounding/evidence-mapper.ts"],"sourcesContent":["// core/engines/grounding/evidence-mapper.ts\r\nimport { Claim } from \"@/core/claims/claim-decomposer\";\r\nimport { ClaimType } from \"../../claims/claim-types\"; \r\n\r\nexport interface EvidenceMatch {\r\n  claimId: string;\r\n  supported: boolean;\r\n  confidence: number;\r\n  sources: string[]; // <--- ADDED THIS (Critical Fix)\r\n  reasoning?: string;\r\n}\r\n\r\n// Mock implementation to satisfy the compiler until you connect real search\r\nexport function mapEvidence(claims: Claim[], sources: string[]): EvidenceMatch[] {\r\n  return claims.map((claim) => ({\r\n    claimId: claim.id,\r\n    supported: Math.random() > 0.3, // Mock logic\r\n    confidence: 0.8,\r\n    sources: sources, // <--- Now strictly assigning the sources to match the interface\r\n    reasoning: \"Matched via semantic similarity vector search.\"\r\n  }));\r\n}"],"names":[],"mappings":"AAAA,4CAA4C;;;;AAarC,SAAS,YAAY,MAAe,EAAE,OAAiB;IAC5D,OAAO,OAAO,GAAG,CAAC,CAAC,QAAU,CAAC;YAC5B,SAAS,MAAM,EAAE;YACjB,WAAW,KAAK,MAAM,KAAK;YAC3B,YAAY;YACZ,SAAS;YACT,WAAW;QACb,CAAC;AACH"}},
    {"offset": {"line": 204, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 209, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/engines/grounding/grounding-engine.ts"],"sourcesContent":["// core/engines/grounding/grounding-engine.ts\r\nimport { EvidenceMatch } from \"./evidence-mapper\"; \r\n\r\nexport function computeGroundingScore(\r\n  matches: EvidenceMatch[]\r\n): number {\r\n  if (matches.length === 0) return 0;\r\n\r\n  const supported = matches.filter(m => m.supported).length;\r\n  // Basic algorithm: % of supported claims\r\n  return Math.round((supported / matches.length) * 100);\r\n}"],"names":[],"mappings":"AAAA,6CAA6C;;;;AAGtC,SAAS,sBACd,OAAwB;IAExB,IAAI,QAAQ,MAAM,KAAK,GAAG,OAAO;IAEjC,MAAM,YAAY,QAAQ,MAAM,CAAC,CAAA,IAAK,EAAE,SAAS,EAAE,MAAM;IACzD,yCAAyC;IACzC,OAAO,KAAK,KAAK,CAAC,AAAC,YAAY,QAAQ,MAAM,GAAI;AACnD"}},
    {"offset": {"line": 219, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 224, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/engines/consistency/consistency-engine.ts"],"sourcesContent":["export function computeConsistencyScore(\r\n  contradictions: string[],\r\n  inferenceGaps: string[]\r\n): number {\r\n  const penalty =\r\n    contradictions.length * 30 + inferenceGaps.length * 15;\r\n\r\n  return Math.max(0, 100 - penalty);\r\n}\r\n"],"names":[],"mappings":";;;AAAO,SAAS,wBACd,cAAwB,EACxB,aAAuB;IAEvB,MAAM,UACJ,eAAe,MAAM,GAAG,KAAK,cAAc,MAAM,GAAG;IAEtD,OAAO,KAAK,GAAG,CAAC,GAAG,MAAM;AAC3B"}},
    {"offset": {"line": 231, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 236, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/engines/risk/hallucination-detector.ts"],"sourcesContent":["import { RiskExplanation } from \"../../risk/types\";\r\nimport { Claim } from \"../../claims/claim-decomposer\";\r\n\r\ntype EvidenceMatch = {\r\n  claimId: string;\r\n  sources: string[];\r\n};\r\n\r\nexport function detectHallucinations(\r\n  claims: Claim[],\r\n  evidenceMatches: EvidenceMatch[]\r\n): RiskExplanation[] {\r\n\r\n  const evidenceByClaim = new Map(\r\n    evidenceMatches.map(e => [e.claimId, e.sources])\r\n  );\r\n\r\n  return claims\r\n    .filter(claim => {\r\n      const sources = evidenceByClaim.get(claim.id);\r\n      return !sources || sources.length === 0;\r\n    })\r\n    .map(claim => ({\r\n      id: `hallucination-${claim.id}`,\r\n      claimId: claim.id,\r\n      type: \"hallucination\",\r\n      severity: \"medium\",\r\n      reasoning: {\r\n        observation:\r\n          \"The claim makes an assertion without referencing supporting evidence.\",\r\n        missing: [\r\n          \"external benchmarks\",\r\n          \"independent validation\",\r\n          \"verifiable data sources\",\r\n        ],\r\n        implication:\r\n          \"This increases the risk that readers may treat speculative statements as factual.\",\r\n      },\r\n      remediation: {\r\n        action:\r\n          \"Explicitly state uncertainty or provide supporting external references.\",\r\n        example:\r\n          \"Internal testing suggests improvements, though no independent benchmarks are available yet.\",\r\n      },\r\n    }));\r\n}\r\n"],"names":[],"mappings":";;;AAQO,SAAS,qBACd,MAAe,EACf,eAAgC;IAGhC,MAAM,kBAAkB,IAAI,IAC1B,gBAAgB,GAAG,CAAC,CAAA,IAAK;YAAC,EAAE,OAAO;YAAE,EAAE,OAAO;SAAC;IAGjD,OAAO,OACJ,MAAM,CAAC,CAAA;QACN,MAAM,UAAU,gBAAgB,GAAG,CAAC,MAAM,EAAE;QAC5C,OAAO,CAAC,WAAW,QAAQ,MAAM,KAAK;IACxC,GACC,GAAG,CAAC,CAAA,QAAS,CAAC;YACb,IAAI,CAAC,cAAc,EAAE,MAAM,EAAE,CAAC,CAAC;YAC/B,SAAS,MAAM,EAAE;YACjB,MAAM;YACN,UAAU;YACV,WAAW;gBACT,aACE;gBACF,SAAS;oBACP;oBACA;oBACA;iBACD;gBACD,aACE;YACJ;YACA,aAAa;gBACX,QACE;gBACF,SACE;YACJ;QACF,CAAC;AACL"}},
    {"offset": {"line": 267, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 272, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/engines/risk/overconfidence-detector.ts"],"sourcesContent":["import { Claim } from \"../../claims/claim-decomposer\";\r\nimport { Tone } from \"../../intake/tone-calibration\";\r\n\r\nexport function detectOverconfidence(\r\n  claims: Claim[],\r\n  tone: Tone\r\n): string[] {\r\n  if (tone !== \"assertive\") return [];\r\n\r\n  return claims\r\n    .filter(c => c.type === \"predictive\" || c.type === \"numerical\")\r\n    .map(c => `Overconfident phrasing in ${c.id}`);\r\n}\r\n"],"names":[],"mappings":";;;AAGO,SAAS,qBACd,MAAe,EACf,IAAU;IAEV,IAAI,SAAS,aAAa,OAAO,EAAE;IAEnC,OAAO,OACJ,MAAM,CAAC,CAAA,IAAK,EAAE,IAAI,KAAK,gBAAgB,EAAE,IAAI,KAAK,aAClD,GAAG,CAAC,CAAA,IAAK,CAAC,0BAA0B,EAAE,EAAE,EAAE,CAAC,CAAC;AACjD"}},
    {"offset": {"line": 279, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 284, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/engines/assumptions/assumption-extractor.ts"],"sourcesContent":["import { Claim } from \"../../claims/claim-decomposer\";\r\n\r\nexport function extractAssumptions(claims: Claim[]): string[] {\r\n  const assumptions: string[] = [];\r\n\r\n  claims.forEach(c => {\r\n    if (c.text.includes(\"assumes\")) {\r\n      assumptions.push(c.text);\r\n    }\r\n  });\r\n\r\n  return assumptions;\r\n}\r\n"],"names":[],"mappings":";;;AAEO,SAAS,mBAAmB,MAAe;IAChD,MAAM,cAAwB,EAAE;IAEhC,OAAO,OAAO,CAAC,CAAA;QACb,IAAI,EAAE,IAAI,CAAC,QAAQ,CAAC,YAAY;YAC9B,YAAY,IAAI,CAAC,EAAE,IAAI;QACzB;IACF;IAEA,OAAO;AACT"}},
    {"offset": {"line": 296, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 301, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/engines/risk/semantic-validator.ts"],"sourcesContent":["// core/engines/risk/semantic-validator.ts\r\nimport { Claim } from \"../../claims/claim-decomposer\";\r\nimport { RiskExplanation } from \"../../risk/types\";\r\nimport { Domain } from \"../../intake/domain-classifier\";\r\n\r\nexport async function detectSemanticViolations(\r\n  claims: Claim[],\r\n  domain: Domain\r\n): Promise<RiskExplanation[]> {\r\n  const risks: RiskExplanation[] = [];\r\n\r\n  for (const claim of claims) {\r\n    // 1. Absolutism Gate\r\n    if (/(100%|guaranteed|impossible to fail|infallible|perfect)/i.test(claim.text)) {\r\n      risks.push(createRisk(claim, \"high\", \"Absolutist phrasing detected. In professional auditing, absolute certainty is a primary red flag for fraud.\"));\r\n    }\r\n\r\n    // 2. Physical/Scientific Law Gate (Entropy/Thermodynamics)\r\n    if (domain === \"research\" && /(entropy|perpetual|over-unity|faster than light)/i.test(claim.text)) {\r\n      risks.push(createRisk(claim, \"high\", \"Violation of fundamental scientific constants. This claim contradicts established physical laws.\"));\r\n    }\r\n\r\n    // 3. Regulatory Gate (Finance/Legal)\r\n    if ((domain === \"finance\" || domain === \"legal\") && /(guaranteed returns|no-risk profit|bypass regulation)/i.test(claim.text)) {\r\n      risks.push(createRisk(claim, \"high\", \"Regulatory compliance violation. Promised returns without risk disclosure are prohibited by financial authorities.\"));\r\n    }\r\n  }\r\n\r\n  return risks;\r\n}\r\n\r\nfunction createRisk(claim: Claim, severity: any, observation: string): RiskExplanation {\r\n  return {\r\n    id: `semantic-${claim.id}`,\r\n    claimId: claim.id,\r\n    type: \"hallucination\",\r\n    severity,\r\n    reasoning: {\r\n      observation,\r\n      implication: \"The entire logical structure of the document is compromised by this impossible premise.\",\r\n    },\r\n    remediation: {\r\n      action: \"Remove absolute qualifiers or provide proof of breakthrough validation.\",\r\n    }\r\n  };\r\n}"],"names":[],"mappings":"AAAA,0CAA0C;;;;AAKnC,eAAe,yBACpB,MAAe,EACf,MAAc;IAEd,MAAM,QAA2B,EAAE;IAEnC,KAAK,MAAM,SAAS,OAAQ;QAC1B,qBAAqB;QACrB,IAAI,2DAA2D,IAAI,CAAC,MAAM,IAAI,GAAG;YAC/E,MAAM,IAAI,CAAC,WAAW,OAAO,QAAQ;QACvC;QAEA,2DAA2D;QAC3D,IAAI,WAAW,cAAc,oDAAoD,IAAI,CAAC,MAAM,IAAI,GAAG;YACjG,MAAM,IAAI,CAAC,WAAW,OAAO,QAAQ;QACvC;QAEA,qCAAqC;QACrC,IAAI,CAAC,WAAW,aAAa,WAAW,OAAO,KAAK,yDAAyD,IAAI,CAAC,MAAM,IAAI,GAAG;YAC7H,MAAM,IAAI,CAAC,WAAW,OAAO,QAAQ;QACvC;IACF;IAEA,OAAO;AACT;AAEA,SAAS,WAAW,KAAY,EAAE,QAAa,EAAE,WAAmB;IAClE,OAAO;QACL,IAAI,CAAC,SAAS,EAAE,MAAM,EAAE,CAAC,CAAC;QAC1B,SAAS,MAAM,EAAE;QACjB,MAAM;QACN;QACA,WAAW;YACT;YACA,aAAa;QACf;QACA,aAAa;YACX,QAAQ;QACV;IACF;AACF"}},
    {"offset": {"line": 338, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 343, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/engines/risk/refutation-engine.ts"],"sourcesContent":["// core/engines/risk/refutation-engine.ts\r\nimport { Claim } from \"../../claims/claim-decomposer\";\r\nimport { LLMProvider } from \"../../../lib/llm/provider-adapter\";\r\nimport { RiskExplanation } from \"../../risk/types\";\r\n\r\nexport async function runAdversarialRefutation(\r\n  claims: Claim[],\r\n  provider: LLMProvider\r\n): Promise<RiskExplanation[]> {\r\n  const risks: RiskExplanation[] = [];\r\n\r\n  // Parallel refutation for speed\r\n  await Promise.all(claims.map(async (claim) => {\r\n    const prompt = `\r\n      Act as a Skeptical Auditor. Your goal is to DEBUNK this claim.\r\n      Identify the specific logical fallacy, missing assumption, or data gap that makes this claim unreliable.\r\n      \r\n      Claim: \"${claim.text}\"\r\n      \r\n      If you find a structural weakness, return a JSON object with \"reason\" and \"implication\". \r\n      Otherwise return null.\r\n    `;\r\n\r\n    const response = await provider.generate({ prompt, temperature: 0.2 });\r\n    try {\r\n      const defect = JSON.parse(response.text);\r\n      if (defect) {\r\n        risks.push({\r\n          id: `refute-${claim.id}`,\r\n          claimId: claim.id,\r\n          type: \"consistency\",\r\n          severity: \"medium\",\r\n          reasoning: {\r\n            observation: defect.reason,\r\n            implication: defect.implication,\r\n          },\r\n          remediation: { action: \"Address the specific logical counter-argument.\" }\r\n        });\r\n      }\r\n    } catch (e) { /* No defect found */ }\r\n  }));\r\n\r\n  return risks;\r\n}"],"names":[],"mappings":"AAAA,yCAAyC;;;;AAKlC,eAAe,yBACpB,MAAe,EACf,QAAqB;IAErB,MAAM,QAA2B,EAAE;IAEnC,gCAAgC;IAChC,MAAM,QAAQ,GAAG,CAAC,OAAO,GAAG,CAAC,OAAO;QAClC,MAAM,SAAS,CAAC;;;;cAIN,EAAE,MAAM,IAAI,CAAC;;;;IAIvB,CAAC;QAED,MAAM,WAAW,MAAM,SAAS,QAAQ,CAAC;YAAE;YAAQ,aAAa;QAAI;QACpE,IAAI;YACF,MAAM,SAAS,KAAK,KAAK,CAAC,SAAS,IAAI;YACvC,IAAI,QAAQ;gBACV,MAAM,IAAI,CAAC;oBACT,IAAI,CAAC,OAAO,EAAE,MAAM,EAAE,CAAC,CAAC;oBACxB,SAAS,MAAM,EAAE;oBACjB,MAAM;oBACN,UAAU;oBACV,WAAW;wBACT,aAAa,OAAO,MAAM;wBAC1B,aAAa,OAAO,WAAW;oBACjC;oBACA,aAAa;wBAAE,QAAQ;oBAAiD;gBAC1E;YACF;QACF,EAAE,OAAO,GAAG,CAAwB;IACtC;IAEA,OAAO;AACT"}},
    {"offset": {"line": 385, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 390, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/reasoning/causal-validator.ts"],"sourcesContent":["// core/reasoning/causal-validator.ts\r\nimport { Claim } from \"../claims/claim-decomposer\";\r\nimport { ReasoningGraph } from \"./graph-builder\";\r\nimport { RiskExplanation } from \"../risk/types\";\r\nimport { LLMProvider } from \"../../lib/llm/provider-adapter\";\r\n\r\n/**\r\n * Advanced Causal Validator:\r\n * Performs structural logic auditing on the connections between claims.\r\n * Identifies \"Leaps of Faith,\" \"Non Sequiturs,\" and \"Unsubstantiated Projections.\"\r\n */\r\nexport async function validateCausalBridgesProduction(\r\n  graph: ReasoningGraph,\r\n  claims: Claim[],\r\n  provider: LLMProvider\r\n): Promise<RiskExplanation[]> {\r\n  const risks: RiskExplanation[] = [];\r\n\r\n  // Parallel analysis for world-class performance\r\n  await Promise.all(\r\n    graph.edges.map(async (edge) => {\r\n      const source = claims.find((c) => c.id === edge.from);\r\n      const target = claims.find((c) => c.id === edge.to);\r\n\r\n      if (!source || !target) return;\r\n\r\n      /* 1. Heuristic Logic Gate: Factual to Predictive Leaps */\r\n      if (source.type === \"factual\" && target.type === \"predictive\") {\r\n        risks.push({\r\n          id: `heuristic-leap-${source.id}-${target.id}`,\r\n          claimId: target.id,\r\n          type: \"consistency\",\r\n          severity: \"medium\",\r\n          reasoning: {\r\n            observation: `Factual-to-Predictive bridge detected between ${source.id} and ${target.id}.`,\r\n            implication: \"The projection assumes current conditions will persist perfectly into the future without external volatility.\",\r\n          },\r\n          remediation: {\r\n            action: \"Add 'Sensitivity Analysis' or state the specific conditions required for this projection to hold true.\",\r\n          },\r\n        });\r\n      }\r\n\r\n      /* 2. Adversarial LLM Logic Audit: Semantic Fallacy Detection */\r\n      const prompt = `\r\n        Act as a Senior McKinsey Strategy Auditor. Analyze the logical bridge between these two claims.\r\n        \r\n        Claim A (Source): \"${source.text}\"\r\n        Claim B (Target): \"${target.text}\"\r\n        \r\n        Task: Does Claim A logically and sufficiently support the conclusion in Claim B?\r\n        Look for:\r\n        - Non Sequitur: The conclusion doesn't follow the premise.\r\n        - Leap of Faith: Target assumes a 100% success rate of an unproven process.\r\n        - Correlation/Causation Fallacy.\r\n\r\n        Return ONLY a JSON object: \r\n        {\"defect\": \"string describing the fallacy\", \"severity\": \"high\" | \"medium\" | \"low\"} \r\n        or return \"null\" if the logic is airtight.\r\n      `;\r\n\r\n      try {\r\n        const response = await provider.generate({ prompt, temperature: 0 });\r\n        const resultText = response.text.replace(/```json|```/g, \"\").trim();\r\n\r\n        if (resultText !== \"null\") {\r\n          const audit = JSON.parse(resultText);\r\n          risks.push({\r\n            id: `logic-bridge-${source.id}-${target.id}`,\r\n            claimId: target.id,\r\n            type: \"consistency\",\r\n            severity: audit.severity,\r\n            reasoning: {\r\n              observation: audit.defect,\r\n              implication: \"Structural logical failure: the conclusion relies on a premise that does not fully substantiate it.\",\r\n            },\r\n            remediation: {\r\n              action: \"Provide the 'missing link' data or weaken the certainty of the conclusion.\",\r\n            },\r\n          });\r\n        }\r\n      } catch (e) {\r\n        // Silent fail for malformed JSON to ensure pipeline continuity\r\n      }\r\n    })\r\n  );\r\n\r\n  return risks;\r\n}"],"names":[],"mappings":"AAAA,qCAAqC;;;;AAW9B,eAAe,gCACpB,KAAqB,EACrB,MAAe,EACf,QAAqB;IAErB,MAAM,QAA2B,EAAE;IAEnC,gDAAgD;IAChD,MAAM,QAAQ,GAAG,CACf,MAAM,KAAK,CAAC,GAAG,CAAC,OAAO;QACrB,MAAM,SAAS,OAAO,IAAI,CAAC,CAAC,IAAM,EAAE,EAAE,KAAK,KAAK,IAAI;QACpD,MAAM,SAAS,OAAO,IAAI,CAAC,CAAC,IAAM,EAAE,EAAE,KAAK,KAAK,EAAE;QAElD,IAAI,CAAC,UAAU,CAAC,QAAQ;QAExB,wDAAwD,GACxD,IAAI,OAAO,IAAI,KAAK,aAAa,OAAO,IAAI,KAAK,cAAc;YAC7D,MAAM,IAAI,CAAC;gBACT,IAAI,CAAC,eAAe,EAAE,OAAO,EAAE,CAAC,CAAC,EAAE,OAAO,EAAE,CAAC,CAAC;gBAC9C,SAAS,OAAO,EAAE;gBAClB,MAAM;gBACN,UAAU;gBACV,WAAW;oBACT,aAAa,CAAC,8CAA8C,EAAE,OAAO,EAAE,CAAC,KAAK,EAAE,OAAO,EAAE,CAAC,CAAC,CAAC;oBAC3F,aAAa;gBACf;gBACA,aAAa;oBACX,QAAQ;gBACV;YACF;QACF;QAEA,8DAA8D,GAC9D,MAAM,SAAS,CAAC;;;2BAGK,EAAE,OAAO,IAAI,CAAC;2BACd,EAAE,OAAO,IAAI,CAAC;;;;;;;;;;;MAWnC,CAAC;QAED,IAAI;YACF,MAAM,WAAW,MAAM,SAAS,QAAQ,CAAC;gBAAE;gBAAQ,aAAa;YAAE;YAClE,MAAM,aAAa,SAAS,IAAI,CAAC,OAAO,CAAC,gBAAgB,IAAI,IAAI;YAEjE,IAAI,eAAe,QAAQ;gBACzB,MAAM,QAAQ,KAAK,KAAK,CAAC;gBACzB,MAAM,IAAI,CAAC;oBACT,IAAI,CAAC,aAAa,EAAE,OAAO,EAAE,CAAC,CAAC,EAAE,OAAO,EAAE,CAAC,CAAC;oBAC5C,SAAS,OAAO,EAAE;oBAClB,MAAM;oBACN,UAAU,MAAM,QAAQ;oBACxB,WAAW;wBACT,aAAa,MAAM,MAAM;wBACzB,aAAa;oBACf;oBACA,aAAa;wBACX,QAAQ;oBACV;gBACF;YACF;QACF,EAAE,OAAO,GAAG;QACV,+DAA+D;QACjE;IACF;IAGF,OAAO;AACT"}},
    {"offset": {"line": 460, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 465, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/scoring/trust-score.ts"],"sourcesContent":["export interface ETSComponents {\r\n  grounding: number;\r\n  consistency: number;\r\n  assumptions: number;\r\n  safety: number;\r\n  security: number;\r\n  calibration: number;\r\n}\r\n\r\nexport function computeETS(\r\n  components: ETSComponents,\r\n  weights: Record<keyof ETSComponents, number>\r\n): number {\r\n  let total = 0;\r\n\r\n  for (const key in components) {\r\n    total += components[key as keyof ETSComponents] *\r\n      weights[key as keyof ETSComponents];\r\n  }\r\n\r\n  return Math.round(total);\r\n}\r\n"],"names":[],"mappings":";;;AASO,SAAS,WACd,UAAyB,EACzB,OAA4C;IAE5C,IAAI,QAAQ;IAEZ,IAAK,MAAM,OAAO,WAAY;QAC5B,SAAS,UAAU,CAAC,IAA2B,GAC7C,OAAO,CAAC,IAA2B;IACvC;IAEA,OAAO,KAAK,KAAK,CAAC;AACpB"}},
    {"offset": {"line": 475, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 480, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/scoring/weighting-profiles.ts"],"sourcesContent":["export const ETS_WEIGHTS = {\r\n  founder: {\r\n    grounding: 0.25,\r\n    consistency: 0.25,\r\n    assumptions: 0.1,\r\n    safety: 0.15,\r\n    security: 0.1,\r\n    calibration: 0.15,\r\n  },\r\n  legal: {\r\n    grounding: 0.3,\r\n    consistency: 0.3,\r\n    assumptions: 0.15,\r\n    safety: 0.15,\r\n    security: 0.05,\r\n    calibration: 0.05,\r\n  },\r\n} as const;\r\n\r\n/* ðŸ‘‡ THIS IS THE KEY LINE */\r\nexport type WeightProfile = keyof typeof ETS_WEIGHTS;\r\n"],"names":[],"mappings":";;;AAAO,MAAM,cAAc;IACzB,SAAS;QACP,WAAW;QACX,aAAa;QACb,aAAa;QACb,QAAQ;QACR,UAAU;QACV,aAAa;IACf;IACA,OAAO;QACL,WAAW;QACX,aAAa;QACb,aAAa;QACb,QAAQ;QACR,UAAU;QACV,aAAa;IACf;AACF"}},
    {"offset": {"line": 501, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 506, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/core/pipelines/verify-pipeline.ts"],"sourcesContent":["// core/pipelines/verify-pipeline.ts\r\nimport { normalizeInput } from \"../intake/normalize\";\r\nimport { calibrateTone } from \"../intake/tone-calibration\";\r\nimport { classifyDomain, Domain } from \"../intake/domain-classifier\";\r\nimport { decomposeClaimsAdvanced, Claim } from \"../claims/claim-decomposer\";\r\nimport { linkClaims } from \"../claims/claim-linker\";\r\nimport { buildGraph } from \"../reasoning/graph-builder\";\r\nimport { detectContradictions } from \"../reasoning/contradiction-checker\";\r\nimport { detectInferenceGaps } from \"../reasoning/inference-gap-detector\";\r\nimport { mapEvidence } from \"../engines/grounding/evidence-mapper\";\r\nimport { computeGroundingScore } from \"../engines/grounding/grounding-engine\";\r\nimport { computeConsistencyScore } from \"../engines/consistency/consistency-engine\";\r\nimport { detectHallucinations } from \"../engines/risk/hallucination-detector\";\r\nimport { detectOverconfidence } from \"../engines/risk/overconfidence-detector\";\r\nimport { extractAssumptions } from \"../engines/assumptions/assumption-extractor\";\r\nimport { detectSemanticViolations } from \"../engines/risk/semantic-validator\";\r\nimport { runAdversarialRefutation } from \"../engines/risk/refutation-engine\";\r\nimport { validateCausalBridgesProduction } from \"../reasoning/causal-validator\";\r\nimport { computeETS, ETSComponents } from \"../scoring/trust-score\";\r\nimport { ETS_WEIGHTS, WeightProfile } from \"../scoring/weighting-profiles\";\r\nimport { RiskExplanation } from \"../risk/types\";\r\nimport { LLMProvider } from \"../../lib/llm/provider-adapter\";\r\n\r\nexport interface VerifyResult {\r\n  score: number;\r\n  claims: Claim[];\r\n  risks: RiskExplanation[];\r\n  explainability: {\r\n    contradictions: string[];\r\n    inferenceGaps: string[];\r\n    overconfidence: string[];\r\n    assumptions: string[];\r\n    auditStatus: \"PASSED\" | \"CRITICAL_FAILURE\";\r\n  };\r\n}\r\n\r\nexport async function verifyPipeline(\r\n  rawText: string,\r\n  profile: WeightProfile,\r\n  provider: LLMProvider,\r\n  sources: string[] = []\r\n): Promise<VerifyResult> {\r\n  const text = normalizeInput(rawText);\r\n  const tone = calibrateTone(text);\r\n  const domain: Domain = classifyDomain(text);\r\n\r\n  // 1. Forensic Decomposition\r\n  const claims = await decomposeClaimsAdvanced(text, provider);\r\n\r\n  // 2. Structural Reasoning\r\n  const links = linkClaims(claims);\r\n  const graph = buildGraph(claims, links);\r\n  const evidenceMatches = mapEvidence(claims, sources);\r\n\r\n  // 3. Parallel Adversarial Analysis (The \"Skeptic\" Layer)\r\n  const [semanticRisks, refutationRisks, causalRisks] = await Promise.all([\r\n    detectSemanticViolations(claims, domain),\r\n    runAdversarialRefutation(claims, provider),\r\n    validateCausalBridgesProduction(graph, claims, provider)\r\n  ]);\r\n\r\n  // 4. Score Components\r\n  const contradictions = detectContradictions(claims);\r\n  const inferenceGaps = detectInferenceGaps(graph);\r\n  const groundingScore = computeGroundingScore(evidenceMatches);\r\n  const consistencyScore = computeConsistencyScore(contradictions, inferenceGaps);\r\n  const hallucinationRisks = detectHallucinations(claims, evidenceMatches);\r\n  const overconfidenceSignals = detectOverconfidence(claims, tone);\r\n  const assumptions = extractAssumptions(claims);\r\n\r\n  const allRisks = [...semanticRisks, ...refutationRisks, ...causalRisks, ...hallucinationRisks];\r\n\r\n  // 5. ETS Component Calculation\r\n  const components: ETSComponents = {\r\n    grounding: groundingScore,\r\n    consistency: consistencyScore,\r\n    assumptions: Math.max(0, 100 - assumptions.length * 10),\r\n    safety: Math.max(0, 100 - allRisks.filter(r => r.severity === \"high\").length * 25),\r\n    security: 100,\r\n    calibration: Math.max(0, 100 - overconfidenceSignals.length * 10),\r\n  };\r\n\r\n  let score = Math.max(0, Math.round(computeETS(components, ETS_WEIGHTS[profile])));\r\n\r\n  // 6. Logic Gate: Structural Failure Check\r\n  const hasCriticalFailure = allRisks.some(r => r.severity === \"high\") || \r\n                            claims.some(c => c.gravity === \"critical\");\r\n  \r\n  if (hasCriticalFailure) {\r\n    score = Math.min(score, 18); // Hard cap for impossible/unsubstantiated claims\r\n  }\r\n\r\n  return {\r\n    score,\r\n    claims,\r\n    risks: allRisks,\r\n    explainability: {\r\n      contradictions,\r\n      inferenceGaps,\r\n      overconfidence: overconfidenceSignals,\r\n      assumptions,\r\n      auditStatus: hasCriticalFailure ? \"CRITICAL_FAILURE\" : \"PASSED\"\r\n    },\r\n  };\r\n}"],"names":[],"mappings":"AAAA,oCAAoC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAoC7B,eAAe,eACpB,OAAe,EACf,OAAsB,EACtB,QAAqB,EACrB,UAAoB,EAAE;IAEtB,MAAM,OAAO,8IAAe;IAC5B,MAAM,OAAO,uJAAc;IAC3B,MAAM,SAAiB,yJAAe;IAEtC,4BAA4B;IAC5B,MAAM,SAAS,MAAM,iKAAwB,MAAM;IAEnD,0BAA0B;IAC1B,MAAM,QAAQ,gJAAW;IACzB,MAAM,QAAQ,oJAAW,QAAQ;IACjC,MAAM,kBAAkB,kKAAY,QAAQ;IAE5C,yDAAyD;IACzD,MAAM,CAAC,eAAe,iBAAiB,YAAY,GAAG,MAAM,QAAQ,GAAG,CAAC;QACtE,6KAAyB,QAAQ;QACjC,4KAAyB,QAAQ;QACjC,4KAAgC,OAAO,QAAQ;KAChD;IAED,sBAAsB;IACtB,MAAM,iBAAiB,sKAAqB;IAC5C,MAAM,gBAAgB,yKAAoB;IAC1C,MAAM,iBAAiB,6KAAsB;IAC7C,MAAM,mBAAmB,mLAAwB,gBAAgB;IACjE,MAAM,qBAAqB,6KAAqB,QAAQ;IACxD,MAAM,wBAAwB,8KAAqB,QAAQ;IAC3D,MAAM,cAAc,gLAAmB;IAEvC,MAAM,WAAW;WAAI;WAAkB;WAAoB;WAAgB;KAAmB;IAE9F,+BAA+B;IAC/B,MAAM,aAA4B;QAChC,WAAW;QACX,aAAa;QACb,aAAa,KAAK,GAAG,CAAC,GAAG,MAAM,YAAY,MAAM,GAAG;QACpD,QAAQ,KAAK,GAAG,CAAC,GAAG,MAAM,SAAS,MAAM,CAAC,CAAA,IAAK,EAAE,QAAQ,KAAK,QAAQ,MAAM,GAAG;QAC/E,UAAU;QACV,aAAa,KAAK,GAAG,CAAC,GAAG,MAAM,sBAAsB,MAAM,GAAG;IAChE;IAEA,IAAI,QAAQ,KAAK,GAAG,CAAC,GAAG,KAAK,KAAK,CAAC,gJAAW,YAAY,uJAAW,CAAC,QAAQ;IAE9E,0CAA0C;IAC1C,MAAM,qBAAqB,SAAS,IAAI,CAAC,CAAA,IAAK,EAAE,QAAQ,KAAK,WACnC,OAAO,IAAI,CAAC,CAAA,IAAK,EAAE,OAAO,KAAK;IAEzD,IAAI,oBAAoB;QACtB,QAAQ,KAAK,GAAG,CAAC,OAAO,KAAK,iDAAiD;IAChF;IAEA,OAAO;QACL;QACA;QACA,OAAO;QACP,gBAAgB;YACd;YACA;YACA,gBAAgB;YAChB;YACA,aAAa,qBAAqB,qBAAqB;QACzD;IACF;AACF"}},
    {"offset": {"line": 607, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 612, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/lib/llm/openai.ts"],"sourcesContent":["import { LLMProvider, LLMRequest, LLMResponse } from \"./provider-adapter\";\r\n\r\nexport class OpenAIProvider implements LLMProvider {\r\n  name = \"openai\";\r\n\r\n  constructor(private apiKey: string) {}\r\n\r\n  async generate(req: LLMRequest): Promise<LLMResponse> {\r\n    const res = await fetch(\"https://api.openai.com/v1/chat/completions\", {\r\n      method: \"POST\",\r\n      headers: {\r\n        Authorization: `Bearer ${this.apiKey}`,\r\n        \"Content-Type\": \"application/json\",\r\n      },\r\n      body: JSON.stringify({\r\n        model: \"gpt-4.1-mini\",\r\n        messages: [{ role: \"user\", content: req.prompt }],\r\n        temperature: req.temperature ?? 0,\r\n      }),\r\n    });\r\n\r\n    const json = await res.json();\r\n\r\n    return {\r\n      text: json.choices[0].message.content,\r\n      model: json.model,\r\n      provider: this.name,\r\n    };\r\n  }\r\n}\r\n"],"names":[],"mappings":";;;AAEO,MAAM;;IACX,KAAgB;IAEhB,YAAY,AAAQ,MAAc,CAAE;aAAhB,SAAA;aAFpB,OAAO;IAE8B;IAErC,MAAM,SAAS,GAAe,EAAwB;QACpD,MAAM,MAAM,MAAM,MAAM,8CAA8C;YACpE,QAAQ;YACR,SAAS;gBACP,eAAe,CAAC,OAAO,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;gBACtC,gBAAgB;YAClB;YACA,MAAM,KAAK,SAAS,CAAC;gBACnB,OAAO;gBACP,UAAU;oBAAC;wBAAE,MAAM;wBAAQ,SAAS,IAAI,MAAM;oBAAC;iBAAE;gBACjD,aAAa,IAAI,WAAW,IAAI;YAClC;QACF;QAEA,MAAM,OAAO,MAAM,IAAI,IAAI;QAE3B,OAAO;YACL,MAAM,KAAK,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO;YACrC,OAAO,KAAK,KAAK;YACjB,UAAU,IAAI,CAAC,IAAI;QACrB;IACF;AACF"}},
    {"offset": {"line": 648, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 653, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/lib/logging/logger.ts"],"sourcesContent":["export type LogLevel = \"info\" | \"warn\" | \"error\";\r\n\r\nexport function log(level: LogLevel, message: string, meta?: unknown) {\r\n  const entry = {\r\n    level,\r\n    message,\r\n    meta,\r\n    timestamp: new Date().toISOString(),\r\n  };\r\n\r\n  console[level](JSON.stringify(entry));\r\n}\r\n"],"names":[],"mappings":";;;AAEO,SAAS,IAAI,KAAe,EAAE,OAAe,EAAE,IAAc;IAClE,MAAM,QAAQ;QACZ;QACA;QACA;QACA,WAAW,IAAI,OAAO,WAAW;IACnC;IAEA,OAAO,CAAC,MAAM,CAAC,KAAK,SAAS,CAAC;AAChC"}},
    {"offset": {"line": 665, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 670, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/app/api/verify/route.ts"],"sourcesContent":["// app/api/verify/route.ts\r\nimport { NextRequest, NextResponse } from \"next/server\";\r\nimport { verifyPipeline } from \"@/core/pipelines/verify-pipeline\";\r\nimport { OpenAIProvider } from \"@/lib/llm/openai\";\r\nimport { log } from \"@/lib/logging/logger\";\r\n\r\nexport async function POST(req: NextRequest) {\r\n  try {\r\n    const body = await req.json();\r\n    const { content, profile, sources = [], userId } = body;\r\n\r\n    if (!content || !profile) {\r\n      return NextResponse.json({ error: \"Missing content or profile\" }, { status: 400 });\r\n    }\r\n\r\n    // Initialize the World's Best Auditor Engine\r\n    const provider = new OpenAIProvider(process.env.OPENAI_API_KEY || \"\");\r\n\r\n    // Must be awaited because the advanced pipeline is async\r\n    const result = await verifyPipeline(\r\n      content,\r\n      profile,\r\n      provider,\r\n      sources\r\n    );\r\n\r\n    log(\"info\", \"Advanced Verification completed\", { userId, score: result.score });\r\n\r\n    return NextResponse.json({ ok: true, result });\r\n  } catch (err: any) {\r\n    log(\"error\", \"Verification failed\", err);\r\n    return NextResponse.json({ error: \"Internal verification error\" }, { status: 500 });\r\n  }\r\n}"],"names":[],"mappings":"AAAA,0BAA0B;;;;;;;;;;;;;AAMnB,eAAe,KAAK,GAAgB;IACzC,IAAI;QACF,MAAM,OAAO,MAAM,IAAI,IAAI;QAC3B,MAAM,EAAE,OAAO,EAAE,OAAO,EAAE,UAAU,EAAE,EAAE,MAAM,EAAE,GAAG;QAEnD,IAAI,CAAC,WAAW,CAAC,SAAS;YACxB,OAAO,wLAAa,IAAI,CAAC;gBAAE,OAAO;YAA6B,GAAG;gBAAE,QAAQ;YAAI;QAClF;QAEA,6CAA6C;QAC7C,MAAM,WAAW,2IAAmB,QAAQ,GAAG,CAAC,cAAc,IAAI;QAElE,yDAAyD;QACzD,MAAM,SAAS,MAAM,0JACnB,SACA,SACA,UACA;QAGF,gIAAI,QAAQ,mCAAmC;YAAE;YAAQ,OAAO,OAAO,KAAK;QAAC;QAE7E,OAAO,wLAAa,IAAI,CAAC;YAAE,IAAI;YAAM;QAAO;IAC9C,EAAE,OAAO,KAAU;QACjB,gIAAI,SAAS,uBAAuB;QACpC,OAAO,wLAAa,IAAI,CAAC;YAAE,OAAO;QAA8B,GAAG;YAAE,QAAQ;QAAI;IACnF;AACF"}},
    {"offset": {"line": 715, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 719, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/.next-internal/server/app/api/verify/route/actions.js"],"sourcesContent":["__turbopack_export_value__({\n});"],"names":[],"mappings":"AAAA,2BAA2B,CAC3B"}},
    {"offset": {"line": 720, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}